# ğŸš€ 03 - Escalamiento BÃ¡sico con HPA (`exp1_basic-autoscaling`)

Este documento describe el primer experimento de elasticidad, en el que se evalÃºa el comportamiento de escalamiento automÃ¡tico de un microservicio bajo una configuraciÃ³n bÃ¡sica de Horizontal Pod Autoscaler (HPA). Se busca observar la respuesta del sistema ante una carga creciente, estimar la demanda de recursos y compararla con la oferta para generar la grÃ¡fica de elasticidad.

---

## ğŸŒŸ Objetivo del experimento

- Observar cÃ³mo responde el sistema ante una carga progresiva.
- Registrar y visualizar los eventos de escalamiento (`scaleup`, `scaledown`).
- Estimar:
  - Demanda total de CPU (en millicores).
  - Oferta de CPU disponible segÃºn nÃºmero de rÃ©plicas activas.
- Usar estos datos para construir la grÃ¡fica de elasticidad del sistema.

---

## âš™ï¸ Arquitectura del experimento

- **Microservicio**: NGINX (mismo usado en el microbenchmark)
- **Cluster**: Kubernetes local
- **Autoscaler**: HPA con target de CPU = 25%
- **Generador de carga**: k6
- **DuraciÃ³n**: 7 minutos de carga variada

> ğŸ” **Requisito previo:** Ejecutar el microbenchmark para obtener las estimaciones de CPU por VU. Los valores resultantes deben actualizarse manualmente en los scripts:
>
> - `plot_elasticity_cpu.py`
> - `plot_elasticity_curve_with_events.py`
>
> Dentro de estos archivos se encuentra la siguiente secciÃ³n:
> ```python
> # ==============================================================================
> # IMPORTANTE: AJUSTAR SEGÃšN MICROBENCHMARK
> # ==============================================================================
> cpu_per_vu = 1.50    # millicores por VU
> cpu_per_req = 0.05   # millicores por request
> requests_per_vu_per_second = 1  # Asumido por diseÃ±o del benchmark (1 request/seg por VU)
> ```

---

## â™»ï¸ Flujo del experimento

| Paso | DescripciÃ³n |
|------|-------------|
| 1. | Despliegue de NGINX y HPA en Kubernetes |
| 2. | IniciaciÃ³n del recolector de mÃ©tricas y eventos |
| 3. | EjecuciÃ³n de la prueba de carga (`basic_autoscaling_test.js`) |
| 4. | RecolecciÃ³n de mÃ©tricas de CPU y nÃºmero de pods |
| 5. | AnÃ¡lisis de demanda vs. oferta con scripts en Python |

---

## ğŸ“¦ Configuraciones utilizadas

### Manifiestos Kubernetes (`manifests/`):
- `deployment.yaml`: despliegue de NGINX con CPU requests/limits definidos.
- `hpa.yaml`: HPA con objetivo de CPU al 25% y entre 1-10 rÃ©plicas.

### Scripts (`scripts/`):
- `basic_autoscaling_test.js`: genera carga con picos y descensos progresivos.
- `capture_deployment_events.sh`: captura los eventos de escalamiento del deployment.
- `metric_collector_basic.sh`: recolecta mÃ©tricas de CPU y nÃºmero de pods.

### Carga generada con:
```js
stages: [
  { duration: '1m', target: 50 },   // Subida progresiva de carga
  { duration: '3m', target: 150 },  // Carga alta sostenida (deberÃ­a activar el HPA)
  { duration: '2m', target: 50 },   // ReducciÃ³n progresiva
  { duration: '1m', target: 0 },    // Descenso total de la carga
]
```

---

## ğŸ” AnÃ¡lisis realizado

### EstimaciÃ³n de demanda
```python
cpu_per_vu = 1.5  # millicores por VU (ajustar segÃºn resultado del microbenchmark)
estimated_demand = vus * cpu_per_vu
```

### EstimaciÃ³n de oferta
```python
offer = replicas * 100  # 100m = CPU request por pod
```

---

## ğŸ“Š Resultados obtenidos

### GrÃ¡ficos generados:
- `cpu_usage_per_pod.png`: Uso de CPU por pod durante la prueba.
- `cpu_usage_per_pod_with_events.png`: Uso de CPU con eventos de escalamiento.
- `pod_count_over_time.png`: EvoluciÃ³n del nÃºmero de pods.
- `pod_count_over_time_with_events.png`: EvoluciÃ³n de pods con eventos.
- `elasticity_curve.png`: ComparaciÃ³n demanda vs. oferta.
- `elasticity_curve_with_events.png`: Curva de elasticidad con eventos.

---

## ğŸ“ Estructura del experimento

```
files/basic-autoscaling/
â”œâ”€â”€ manifests/                        # YAMLs de Kubernetes (deployment, HPA)
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â””â”€â”€ hpa.yaml
â”œâ”€â”€ scripts/                          # Scripts ejecutables del experimento
â”‚   â”œâ”€â”€ basic_autoscaling_test.js     # Script k6 para generar la carga
â”‚   â”œâ”€â”€ capture_deployment_events.sh  # Captura eventos de escalamiento
â”‚   â””â”€â”€ metric_collector_basic.sh     # Recolector de mÃ©tricas de CPU y pods
â”œâ”€â”€ output/                           # Resultados crudos del experimento
â”‚   â”œâ”€â”€ basic_metrics.csv             # MÃ©tricas CPU y rÃ©plicas
â”‚   â”œâ”€â”€ k6_summary.json               # Resumen de carga generada por k6
â”‚   â”œâ”€â”€ k6_start_time.txt             # Timestamp de inicio de carga
â”‚   â”œâ”€â”€ scaling_events.csv            # Eventos crudos del deployment
â”‚   â””â”€â”€ scaling_events_clean.csv      # Eventos filtrados y sincronizados
â”œâ”€â”€ analysis/                         # Scripts y visualizaciones
â”‚   â”œâ”€â”€ Dockerfile                    # Contenedor para reproducir anÃ¡lisis
â”‚   â”œâ”€â”€ filter_scaling_events.py      # Limpieza y sincronizaciÃ³n de eventos
â”‚   â”œâ”€â”€ plot_cpu_usage.py             # GrÃ¡fico de CPU por pod
â”‚   â”œâ”€â”€ plot_cpu_usage_with_events.py # CPU con eventos
â”‚   â”œâ”€â”€ plot_pod_count.py             # EvoluciÃ³n de rÃ©plicas
â”‚   â”œâ”€â”€ plot_pod_count_with_events.py # RÃ©plicas con eventos
â”‚   â”œâ”€â”€ plot_elasticity_curve.py      # GrÃ¡fica de demanda vs. oferta
â”‚   â”œâ”€â”€ plot_elasticity_curve_with_events.py # VersiÃ³n con eventos
â”‚   â”œâ”€â”€ requirements.txt              # Dependencias del anÃ¡lisis
â”‚   â””â”€â”€ images/                       # GrÃ¡ficos generados
â”‚       â”œâ”€â”€ cpu_usage_per_pod.png
â”‚       â”œâ”€â”€ cpu_usage_per_pod_with_events.png
â”‚       â”œâ”€â”€ pod_count_over_time.png
â”‚       â”œâ”€â”€ pod_count_over_time_with_events.png
â”‚       â”œâ”€â”€ elasticity_curve.png
â”‚       â”œâ”€â”€ elasticity_curve_with_events.png
â”‚       â””â”€â”€ cpu_pod/                  # GrÃ¡ficos individuales por pod
â”‚           â”œâ”€â”€ pod1_cpu.png
â”‚           â”œâ”€â”€ pod1_cpu_with_events.png
â”‚           â”œâ”€â”€ pod2_cpu.png
â”‚           â””â”€â”€ pod2_cpu_with_events.png
```

---

## ğŸ§¾ Salidas del experimento

âœ… **[Completado]** El experimento bÃ¡sico de elasticidad ha finalizado exitosamente.

**Archivos generados:**
- MÃ©tricas del sistema: `basic-autoscaling/output/basic_metrics.csv`
- Resumen de carga (k6): `basic-autoscaling/output/k6_summary.json`
- Timestamp de inicio k6: `basic-autoscaling/output/k6_start_time.txt`
- Eventos del deployment: `basic-autoscaling/output/scaling_events.csv`
- Eventos limpios: `basic-autoscaling/output/scaling_events_clean.csv`

**ImÃ¡genes generadas:**
- CPU por pod: `analysis/images/cpu_usage_per_pod.png`
- CPU por pod + eventos: `analysis/images/cpu_usage_per_pod_with_events.png`
- EvoluciÃ³n de pods: `analysis/images/pod_count_over_time.png`
- Pods + eventos: `analysis/images/pod_count_over_time_with_events.png`
- Elasticidad: `analysis/images/elasticity_curve.png`
- Elasticidad + eventos: `analysis/images/elasticity_curve_with_events.png`
- Por pod (individual): `analysis/images/cpu_pod/*.png`

---

## ğŸ¤– AutomatizaciÃ³n del proceso

El flujo completo del experimento puede ejecutarse automÃ¡ticamente mediante el script `exp1_basic-autoscaling.sh`, ubicado en la raÃ­z del proyecto.

### ğŸ“ UbicaciÃ³n
```
files/exp1_basic-autoscaling.sh
```

### â–¶ï¸ EjecuciÃ³n
Este script debe ejecutarse desde la raÃ­z del proyecto:
```bash
bash exp1_basic-autoscaling.sh
```

### ğŸ”„ QuÃ© realiza automÃ¡ticamente

1. Aplica los manifiestos en Kubernetes:
```bash
kubectl apply -f basic-autoscaling/manifests/deployment.yaml
kubectl apply -f basic-autoscaling/manifests/hpa.yaml
```

2. Solicita al usuario actualizar la IP del clÃºster en el script de k6.

3. Lanza el recolector de mÃ©tricas y la captura de eventos en segundo plano:
```bash
bash basic-autoscaling/scripts/metric_collector_basic.sh &
bash basic-autoscaling/scripts/capture_deployment_events.sh &
```

4. Ejecuta la prueba con k6 y exporta el resumen:
```bash
k6 run --summary-export basic-autoscaling/output/k6_summary.json \
  basic-autoscaling/scripts/basic_autoscaling_test.js
```

5. Espera 30 segundos y luego detiene los recolectores:
```bash
kill $METRIC_PID
kill $EVENTS_PID
```

6. Construye y ejecuta el contenedor de anÃ¡lisis:
```bash
docker build -t basic-autoscaling-analysis basic-autoscaling/analysis

docker run --rm \
  -v "$(pwd)/basic-autoscaling/output:/app/output" \
  -v "$(pwd)/basic-autoscaling/analysis/files:/app/files" \
  -v "$(pwd)/basic-autoscaling/analysis/images:/app/images" \
  basic-autoscaling-analysis
```

7. Limpia los recursos de Kubernetes:
```bash
kubectl delete -f basic-autoscaling/manifests/deployment.yaml
kubectl delete -f basic-autoscaling/manifests/hpa.yaml
```

Este enfoque garantiza reproducibilidad, facilita la recolecciÃ³n de datos y reduce errores humanos durante la ejecuciÃ³n del experimento. y minimiza errores humanos al ejecutar el experimento completo de elasticidad.

