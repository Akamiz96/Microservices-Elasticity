# Medici√≥n de Elasticidad en Kubernetes

Este documento describe un experimento para medir la elasticidad de un despliegue en Kubernetes utilizando **Horizontal Pod Autoscaler (HPA)** y pruebas de carga con **k6**.

## üìå Objetivo
El objetivo de esta prueba es observar c√≥mo **Kubernetes** escala autom√°ticamente los pods de una aplicaci√≥n en respuesta a la carga, utilizando el **Horizontal Pod Autoscaler (HPA)**.

---

## üöÄ Paso 1: Desplegar la Aplicaci√≥n en Kubernetes

Creamos un archivo YAML llamado **`nginx-deployment.yaml`** para desplegar un servicio basado en **Nginx**:
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-test
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx-test
  template:
    metadata:
      labels:
        app: nginx-test
    spec:
      containers:
      - name: nginx
        image: nginx
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "200m"
            memory: "256Mi"
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx-test
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
      nodePort: 30080
  type: NodePort
```
**Este archivo tambi√©n se encuentra como `files/scalability_test/nginx-deployment.yaml`**

Aplicamos la configuraci√≥n:
```bash
kubectl apply -f files/scalability_test/nginx-deployment.yaml
```

---

## üîß Paso 2: Configurar el Horizontal Pod Autoscaler (HPA)

Creamos un archivo YAML llamado **`hpa.yaml`** para configurar el autoescalado:
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nginx-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx-test
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 25
```
**Este archivo tambi√©n se encuentra como `files/scalability_test/hpa.yaml`**

Aplicamos la configuraci√≥n:
```bash
kubectl apply -f files/scalability_test/hpa.yaml
```

Verificamos el estado del **HPA**:
```bash
kubectl get hpa
```

Si el **HPA** no recolecta m√©tricas correctamente, debemos instalar el **Metrics Server**:
```bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

Luego, activamos la opci√≥n **--kubelet-insecure-tls**:
```bash
kubectl patch deployment metrics-server -n kube-system --type='json' -p='[{"op":"add","path":"/spec/template/spec/containers/0/args/-", "value":"--kubelet-insecure-tls"}]'
```

Verificamos que el **Metrics Server** est√© en ejecuci√≥n:
```bash
kubectl get pods -n kube-system | grep metrics-server
```

---

## üåê Paso 3: Ejecutar Pruebas de Carga con k6

Creamos un archivo **`test.js`** con el siguiente contenido:
```javascript
import http from 'k6/http';
import { sleep } from 'k6';

export let options = {
    stages: [
        { duration: '30s', target: 50 },  // Aumento gradual de carga
        { duration: '1m', target: 200 },  // Mantener carga media
        { duration: '2m', target: 500 },  // Alta carga sostenida
        { duration: '30s', target: 0 }    // Descenso gradual de carga
    ],
};

export default function () {
    http.get('http://<IP_DEL_CLUSTER>:30080');
    sleep(1);
}
```
**Este archivo tambi√©n se encuentra como `files/scalability_test/test.js`**

Reemplaza `<IP_DEL_CLUSTER>` con la IP del nodo donde est√° corriendo el servicio:
```bash
kubectl get nodes -o wide
```

Ejecutamos la prueba de carga con **k6**:
```bash
k6 run files/scalability_test/test.js
```

---

## üìä Paso 4: Monitoreo del Autoescalado

Podemos monitorear en tiempo real c√≥mo se ajustan los recursos observando el **HPA**:
```bash
kubectl get hpa -w
```

Tambi√©n podemos ver el consumo de recursos con:
```bash
kubectl top pods
```

A medida que la carga aumenta, Kubernetes debe crear m√°s **r√©plicas** del **nginx-test** hasta alcanzar el l√≠mite de **10 pods**.

---

## ‚öôÔ∏è Uso del Script Automatizado

Todos los pasos anteriores pueden ejecutarse de forma autom√°tica utilizando el siguiente script:

```bash
files/02_escalability_test.sh
```

### üß™ Ejecuci√≥n del Script

1. Aseg√∫rate de que el archivo tenga permisos de ejecuci√≥n:
```bash
chmod +x files/02_escalability_test.sh
```

2. Ejecuta el script:
```bash
./files/02_escalability_test.sh
```

Este script:
- Despliega la aplicaci√≥n.
- Aplica la configuraci√≥n del HPA.
- Lanza la prueba de carga con `k6`.
- Ejecuta el monitoreo en segundo plano.
- Presenta los resultados autom√°ticamente.

---
## üßπ Limpieza de Recursos

Una vez finalizada la prueba, puedes liberar los recursos creados (deployment, servicio y HPA) para dejar el cl√∫ster limpio.

### Opci√≥n 1: Limpieza autom√°tica al final del script

El script `files/02_escalability_test.sh` te preguntar√° si deseas eliminar los recursos creados. Si respondes `y`, ejecutar√° autom√°ticamente:

```bash
kubectl delete deployment nginx-test
kubectl delete service nginx-service
kubectl delete hpa nginx-hpa
```

Esto eliminar√° los pods y configuraciones utilizadas durante el experimento.

### Opci√≥n 2: Limpieza manual

Si ejecutaste la prueba paso a paso, puedes eliminar los recursos manualmente con los siguientes comandos:

```bash
kubectl delete deployment nginx-test
kubectl delete service nginx-service
kubectl delete hpa nginx-hpa
```

---

## ‚úÖ Conclusi√≥n

Este experimento demuestra c√≥mo Kubernetes ajusta din√°micamente los recursos en respuesta a la demanda. Si el autoescalado funciona correctamente, veremos un aumento progresivo en el n√∫mero de pods hasta que la carga se reduzca nuevamente.
